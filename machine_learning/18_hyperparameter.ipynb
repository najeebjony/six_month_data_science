{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Hyperparameter Tuning \n",
    "\n",
    "\n",
    "## Introduction\n",
    "Hyperparameters are the configuration variables that define how a machine learning model will be trained. They control aspects of the training process, such as the learning\n",
    "algorithm, the number of epochs, and the learning rate. Hyperparameters are used to optimize the model's performance.\n",
    "\n",
    "Types:\n",
    "\n",
    "- Random Search: \n",
    "- Grid Search\n",
    "- Bayesian Optimization\n",
    "- Gradient-based Opyimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation\n",
    "\n",
    "Cross-validation is a technique for evaluating ML models by training several ML models on subsets of the available input data and evaluating them on the complementary subset of the data. In k-fold cross-validation, you split the input data into k subsets of data (also known as folds). You then iterate over each fold, treating it as a held out validation set, and train a model on the remaining k-1 folds (also known as training data). You then calculate the evaluation metric for each of the models on their respective held out validation sets and combine the result into a single metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split ,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score , confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data \n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    " \n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\miniconda3\\envs\\ML_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parametters:{'criterion': 'gini', 'max_depth': 4, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# define the model \n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# create the parametter Grid\n",
    "param_grid = {'n_estimators': [50,100,200,300,400,500], \n",
    "              'max_depth': [4,5,6,7,8,9,10],\n",
    "            #   'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "              'criterion' : ['gini', 'entropy'],\n",
    "            #   'bootstrap'  : [True,False]           \n",
    "              }\n",
    "# initialize the grid search object\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid = param_grid,\n",
    "    cv=5,\n",
    "    scoring = 'f1',\n",
    "    verbose=1,\n",
    "    n_jobs = -1\n",
    ")\n",
    "# fith the model \n",
    "grid.fit(X, y)\n",
    "\n",
    "# print the best score\n",
    "print(f'Best Parametters:{grid.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parametters:{'n_estimators': 200, 'max_depth': 9, 'criterion': 'entropy', 'bootstrap': True}\n",
      "CPU times: total: 875 ms\n",
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model = RandomForestClassifier()\n",
    "# create the parametter Grid\n",
    "param_grid = {'n_estimators': [50,100,200,300,400,500], \n",
    "              'max_depth': [4,5,6,7,8,9,10],\n",
    "            #   'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "              'criterion' : ['gini', 'entropy'],\n",
    "              'bootstrap'  : [True,False]           \n",
    "              }\n",
    "# initialize the grid search object\n",
    "grid = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions= param_grid,\n",
    "    cv=5,\n",
    "    scoring = 'accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs = -1,\n",
    "    n_iter=20\n",
    ")\n",
    "# fith the model \n",
    "grid.fit(X, y)\n",
    "\n",
    "# print the best score\n",
    "print(f'Best Parametters:{grid.best_params_}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
